{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class LGBMWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.model = lgb.LGBMClassifier(**kwargs)\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.model.predict_proba(X)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return self.kwargs\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        self.kwargs.update(params)\n",
        "        return self\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/data.csv')\n",
        "\n",
        "interaction_features = {\n",
        "    'JobSatisfaction_EnvSatisfaction': data['JobSatisfaction'] * data['EnvironmentSatisfaction'],\n",
        "    'YearsInCurrentRole_JobInvolvement': data['YearsInCurrentRole'] * data['JobInvolvement'],\n",
        "    'TotalWorkingYears_Education': data['TotalWorkingYears'] * data['Education'],\n",
        "    'PerformanceRating_Incentive': data['PerformanceRating'] * data['Incentive'],\n",
        "    'YearsAtCompany_Incentive': data['YearsAtCompany'] * data['Incentive'],\n",
        "    'DistanceFromHome_WorkLifeBalance': data['DistanceFromHome'] * data['WorkLifeBalance'],\n",
        "    'WorkLifeBalance_JobSatisfaction': data['WorkLifeBalance'] * data['JobSatisfaction'],\n",
        "    'Age_to_JobSatisfaction': data['Age'] / (data['JobSatisfaction'] + 1),\n",
        "    'MonthlyIncome_to_JobLevel': data['MonthlyIncome'] / (data['JobLevel'] + 1),\n",
        "}\n",
        "data = data.assign(**interaction_features)\n",
        "\n",
        "data['Attrition'] = data['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "X = data.drop(columns=['Attrition', 'EmployeeCount', 'EmployeeNumber'])\n",
        "y = data['Attrition']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "numerical_columns = X.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_columns),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = dict(zip(np.unique(y), class_weights))\n",
        "\n",
        "base_models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight=class_weight_dict),\n",
        "    'Decision Tree': DecisionTreeClassifier(class_weight=class_weight_dict),\n",
        "    'Random Forest': RandomForestClassifier(class_weight=class_weight_dict),\n",
        "    'XGBoost': XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        scale_pos_weight=class_weights[1]/class_weights[0]\n",
        "    )\n",
        "}\n",
        "\n",
        "try:\n",
        "    base_models['LightGBM'] = LGBMWrapper(class_weight='balanced')\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing LightGBM: {str(e)}\")\n",
        "\n",
        "param_grid_rf = {\n",
        "    'clf__n_estimators': [50, 100, 200],\n",
        "    'clf__max_depth': [3, 5, 10, None],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in base_models.items():\n",
        "    try:\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('clf', model)\n",
        "        ])\n",
        "\n",
        "        if name == 'Random Forest':\n",
        "            grid = RandomizedSearchCV(\n",
        "                estimator=pipeline,\n",
        "                param_distributions=param_grid_rf,\n",
        "                cv=5,\n",
        "                n_jobs=-1,\n",
        "                scoring='accuracy',\n",
        "                random_state=42\n",
        "            )\n",
        "            grid.fit(X_train, y_train)\n",
        "            y_pred = grid.predict(X_test)\n",
        "            y_pred_proba = grid.predict_proba(X_test)\n",
        "\n",
        "            results[name] = {\n",
        "                'Best Params': grid.best_params_,\n",
        "                'Model': grid.best_estimator_\n",
        "            }\n",
        "        else:\n",
        "            pipeline.fit(X_train, y_train)\n",
        "            y_pred = pipeline.predict(X_test)\n",
        "            y_pred_proba = pipeline.predict_proba(X_test)\n",
        "            results[name] = {'Model': pipeline}\n",
        "\n",
        "        results[name].update({\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'F1 Score': f1_score(y_test, y_pred),\n",
        "            'AUC': roc_auc_score(y_test, y_pred_proba[:, 1]),\n",
        "            'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
        "            'Classification Report': classification_report(y_test, y_pred)\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
        "    print(f\"AUC: {metrics['AUC']:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(metrics['Confusion Matrix'])\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(metrics['Classification Report'])\n",
        "\n",
        "    if 'Best Params' in metrics:\n",
        "        print(\"\\nBest Parameters:\")\n",
        "        print(metrics['Best Params'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k4LzkZNPBkO",
        "outputId": "4655fbe2-15a7-40f3-e136-f295227e70b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:34:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The XGBClassifier or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training XGBoost: 'super' object has no attribute '__sklearn_tags__'\n",
            "[LightGBM] [Info] Number of positive: 172, number of negative: 857\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2498\n",
            "[LightGBM] [Info] Number of data points in the train set: 1029, number of used features: 67\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.7664\n",
            "F1 Score: 0.5072\n",
            "AUC: 0.8383\n",
            "\n",
            "Confusion Matrix:\n",
            "[[285  91]\n",
            " [ 12  53]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.76      0.85       376\n",
            "           1       0.37      0.82      0.51        65\n",
            "\n",
            "    accuracy                           0.77       441\n",
            "   macro avg       0.66      0.79      0.68       441\n",
            "weighted avg       0.87      0.77      0.80       441\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.8118\n",
            "F1 Score: 0.3465\n",
            "AUC: 0.6160\n",
            "\n",
            "Confusion Matrix:\n",
            "[[336  40]\n",
            " [ 43  22]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       376\n",
            "           1       0.35      0.34      0.35        65\n",
            "\n",
            "    accuracy                           0.81       441\n",
            "   macro avg       0.62      0.62      0.62       441\n",
            "weighted avg       0.81      0.81      0.81       441\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.8662\n",
            "F1 Score: 0.3059\n",
            "AUC: 0.7897\n",
            "\n",
            "Confusion Matrix:\n",
            "[[369   7]\n",
            " [ 52  13]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       376\n",
            "           1       0.65      0.20      0.31        65\n",
            "\n",
            "    accuracy                           0.87       441\n",
            "   macro avg       0.76      0.59      0.62       441\n",
            "weighted avg       0.84      0.87      0.83       441\n",
            "\n",
            "\n",
            "Best Parameters:\n",
            "{'clf__n_estimators': 200, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 2, 'clf__max_depth': None}\n",
            "LightGBM Results:\n",
            "Accuracy: 0.8912\n",
            "F1 Score: 0.5385\n",
            "AUC: 0.7905\n",
            "\n",
            "Confusion Matrix:\n",
            "[[365  11]\n",
            " [ 37  28]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       376\n",
            "           1       0.72      0.43      0.54        65\n",
            "\n",
            "    accuracy                           0.89       441\n",
            "   macro avg       0.81      0.70      0.74       441\n",
            "weighted avg       0.88      0.89      0.88       441\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}